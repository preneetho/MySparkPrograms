import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf

object YouTube{
        def main(args: Array[String]): Unit = {
          // Read the CSV file
        val conf = new SparkConf().setAppName("MyTube")
        val sc = new SparkContext(conf)
          val csv =sc.textFile("hdfs:/preneeth_hdfs/youtubedataNew.txt")
          // split / clean data
          val headerAndRows = csv.map(line => line.split("\t").map(_.trim))
          // get header
          val header = headerAndRows.first
          // filter out header (eh. just check if the first val matches the first header name)
          val data = headerAndRows.filter(_(0) != header(0))
          // splits to map (header/value pairs)
          val maps = data.map(splits => header.zip(splits).toMap)
          // filter out the user "me"
          //val result = maps.filter(map => map("COL4") == "Comedy")
          // print result
          maps.foreach(println)
        sc.stop
        }
}
